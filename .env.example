# LLM Provider (at least one required for analysis)
ANTHROPIC_API_KEY=
OPENAI_API_KEY=

# LLM Models (comma-separated — first entry is primary, rest are fallbacks)
# If the primary model fails, the next model in the chain is tried automatically.
LITELLM_MODEL_CHAIN="openai/gpt-4.1-mini,openai/gpt-4.0-mini"
LLM_MAX_CONCURRENCY=2
LLM_TIMEOUT_SECONDS=60

# Database
DATABASE_URL=sqlite:///data/artifactor.db

# LanceDB + Embeddings (vector RAG)
LANCEDB_URI=data/lancedb
LITELLM_EMBEDDING_MODEL=openai/text-embedding-3-small
RAG_VECTOR_TOP_K=10

# Directories
DATA_DIR=data
LOG_DIR=logs
STATIC_DIR=static

# Logging
LOG_LEVEL=INFO
DEBUG_MODE=false

# Analysis tuning
ANALYSIS_TIMEOUT_SECONDS=900
ANALYSIS_MAX_CONCURRENCY=5
MAX_REPO_SIZE_BYTES=2147483648

# API authentication (empty = no auth; set when exposing on a network)
API_KEY=

# CORS (comma-separated origins, empty = no CORS headers)
CORS_ORIGINS=http://localhost:3000

# Filesystem browsing root (empty = home directory)
BROWSE_ROOT=

# Frontend → Backend URL (used by Next.js)
BACKEND_URL=http://localhost:8000

# Ingestion
MAX_CHUNK_SIZE_TOKENS=6000
MIN_CHUNK_SIZE_LINES=10
CHUNK_OVERLAP_LINES=50

# Observability (optional)
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=artifactor
OTEL_ENABLED=false
TRACE_ENABLED=true
